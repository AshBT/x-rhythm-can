{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # only relevant to my own environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assume that you have downloaded MIDI dataset and uncompssed into `./midi_dataset/groove/` folder  \n",
    "https://magenta.tensorflow.org/datasets/groove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRUM_CLASSES = [\n",
    "   'Kick',\n",
    "   'Snare',\n",
    "   'Hi-hat closed',\n",
    "   'Hi-hat open',\n",
    "   'Tom low',\n",
    "   'Tom mid', \n",
    "   'Tom high',\n",
    "   'Clap',\n",
    "   'Rim' \n",
    "]\n",
    "MIDI_DRUM_MAP = {\n",
    "   36: 0,\n",
    "   35: 0,\n",
    "   38: 1,\n",
    "   27: 1,\n",
    "   28: 1,\n",
    "   31: 1,\n",
    "   32: 1,\n",
    "   33: 1,\n",
    "   34: 1,\n",
    "   37: 1,\n",
    "   39: 1,\n",
    "   40: 1,\n",
    "   56: 1,\n",
    "   65: 1,\n",
    "   66: 1,\n",
    "   75: 1,\n",
    "   85: 1,\n",
    "   42: 2,\n",
    "   44: 2,\n",
    "   54: 2,\n",
    "   68: 2,\n",
    "   69: 2,\n",
    "   70: 2,\n",
    "   71: 2,\n",
    "   73: 2,\n",
    "   78: 2,\n",
    "   80: 2,\n",
    "   46: 3,\n",
    "   67: 3,\n",
    "   72: 3,\n",
    "   74: 3,\n",
    "   79: 3,\n",
    "   81: 3,\n",
    "   45: 4,\n",
    "   29: 4,\n",
    "   41: 4,\n",
    "   61: 4,\n",
    "   64: 4,\n",
    "   84: 4,\n",
    "   48: 5,\n",
    "   47: 5,\n",
    "   60: 5,\n",
    "   63: 5,\n",
    "   77: 5,\n",
    "   86: 5,\n",
    "   87: 5,\n",
    "   50: 6,\n",
    "   30: 6,\n",
    "   43: 6,\n",
    "   62: 6,\n",
    "   76: 6,\n",
    "   83: 6,\n",
    "   49: 7,\n",
    "   55: 7,\n",
    "   57: 7,\n",
    "   58: 7,\n",
    "   51: 8,\n",
    "   52: 8,\n",
    "   53: 8,\n",
    "   59: 8,\n",
    "   82: 8\n",
    "}\n",
    "\n",
    "resolution  = 4 # separate quater into 4  = 16 notes per bar\n",
    "\n",
    "nb_bars = 2 \n",
    "\n",
    "len_seq = resolution * 4 * nb_bars # length of drumloops in training data - 2 bars\n",
    "    \n",
    "nb_notes = len(DRUM_CLASSES) # number of possible MIDI notes  - max_drum_note - min_drum_note\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Old Skool' u'Trance' u'DnB' u'Basic' u'Downtempo' u'Jungle' u'House'\n",
      " u'Breakbeat' u'Garage' u'Techno']\n",
      "(49003,)\n",
      "[0, 2, 5, 6, 7, 8, 9]\n",
      "[u'Old Skool', u'DnB', u'Jungle', u'House', u'Breakbeat', u'Garage', u'Techno']\n",
      "7 genres we have\n",
      "(37950, 32, 9)\n",
      "(37950,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrices_drums = np.load(\"./tmp/matrices_drum_gm_electronic.npz\")['drum_data']\n",
    "matrices_genres = np.load(\"./tmp/matrices_drum_gm_electronic.npz\")['genre_ids']\n",
    "GENRES_ALL = np.load(\"./tmp/matrices_drum_gm_electronic.npz\")['genres']\n",
    "\n",
    "print(GENRES_ALL)\n",
    "print(matrices_genres.shape)\n",
    "\n",
    "# Filter genres \n",
    "GENRES_USED = [u'Old Skool', u'DnB', u'Jungle', u'House', u'Breakbeat', u'Garage', u'Techno']\n",
    "GENRES_ID_USED = [i for i, genre in enumerate(GENRES_ALL) if genre in GENRES_USED]\n",
    "GENRES = [genre for i, genre in enumerate(GENRES_ALL) if genre in GENRES_USED]\n",
    "\n",
    "print(GENRES_ID_USED)\n",
    "print(GENRES)\n",
    "\n",
    "NB_GENRES = len(GENRES)\n",
    "print(\"%d genres we have\" % NB_GENRES)\n",
    "\n",
    "_drums = []\n",
    "_genres = []\n",
    "\n",
    "for genre_id, drum in zip(matrices_genres, matrices_drums):\n",
    "    if genre_id in GENRES_ID_USED:\n",
    "        _drums.append(drum)\n",
    "        genre_id = GENRES_ID_USED.index(genre_id)\n",
    "        _genres.append(genre_id)\n",
    "\n",
    "matrices_drums = np.array(_drums)\n",
    "print(matrices_drums.shape)\n",
    "matrices_genres = np.array(_genres)\n",
    "print(matrices_genres.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0826 14:42:39.566085 140360265770368 deprecation_wrapper.py:119] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0826 14:42:39.580029 140360265770368 deprecation_wrapper.py:119] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0826 14:42:39.583058 140360265770368 deprecation_wrapper.py:119] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Reshape, LSTM, Bidirectional\n",
    "from keras.layers import Embedding, Concatenate\n",
    "from keras.layers.convolutional import Conv2D\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "batch_size = 16\n",
    "n_z = 4\n",
    "dropout_rate = 0.30\n",
    "\n",
    "# encoder\n",
    "drum_input = Input(shape=(len_seq, nb_notes), name='drum_input')  # tensorflow order\n",
    "\n",
    "# # Conditioning label:\n",
    "# # Integer 0-NB_GENRES denoting the genre G should generate\n",
    "# label_input = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "# # Embedding layer:\n",
    "# # Turns labels into dense vectors of size z_dim\n",
    "# # Produces 3D tensor with shape: (batch_size, 1, 28*28*1)\n",
    "# label_embedding = Embedding(NB_GENRES, np.prod((len_seq, nb_notes)), input_length=1)(label_input)\n",
    "\n",
    "# # Flatten the embedding 3D tensor into 2D tensor with shape:(batch_size, 28*28*1)\n",
    "# label_embedding = Flatten()(label_embedding)\n",
    "\n",
    "# # Reshape label embeddings to have same dimensions as input images\n",
    "# label_embedding = Reshape((len_seq, nb_notes))(label_embedding)\n",
    "\n",
    "# # Concatenate images with corresponding label embeddings\n",
    "# concatenated = Concatenate(axis=-1)([drum_input, label_embedding])\n",
    "\n",
    "\n",
    "x = Bidirectional(LSTM(64, return_sequences=True, activation='tanh'))(drum_input) \n",
    "x = Bidirectional(LSTM(128, return_sequences=True, activation='tanh'))(x)\n",
    "x = Bidirectional(LSTM(16, return_sequences=True, activation='tanh'))(x)\n",
    "x1 = Reshape((1024,))(x)\n",
    "\n",
    "x = Dense(512)(x1)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "x = Dense(256)(x)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "output = Dense(1, activation='sigmoid', name='gan_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Softmax\n",
    "\n",
    "# genre classifier\n",
    "# x = Bidirectional(LSTM(64, return_sequences=True, activation='tanh'))(drum_input) \n",
    "# x = Bidirectional(LSTM(128, return_sequences=True, activation='tanh'))(x)\n",
    "# x = Bidirectional(LSTM(16, return_sequences=True, activation='tanh'))(x)\n",
    "# x1 = Reshape((1024,))(x)\n",
    "\n",
    "x = Dense(512)(x1)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "x = Dense(256)(x)\n",
    "x = LeakyReLU(alpha=0.01)(x)\n",
    "x = Dense(NB_GENRES)(x)\n",
    "genre_output = Softmax(name='style_output')(x)\n",
    "\n",
    "# genre_model = Model(drum_input, genre_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pre-trained genre classification model\n",
    "#genre_model.load_weights(\"./tmp/rythm_classification_gm_12-0.30.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 14:42:40.910964 140360265770368 deprecation_wrapper.py:119] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0826 14:42:40.916881 140360265770368 deprecation_wrapper.py:119] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0826 14:42:40.921581 140360265770368 deprecation.py:323] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "drum_input (InputLayer)         (None, 32, 9)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 32, 128)      37888       drum_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 32, 256)      263168      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 32, 32)       34944       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1024)         0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          524800      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          524800      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          131328      leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 256)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 7)            1799        leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gan_output (Dense)              (None, 1)            257         leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "style_output (Softmax)          (None, 7)            0           dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,650,312\n",
      "Trainable params: 1,650,312\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_c = Model(drum_input, [output, genre_output])\n",
    "discriminator_c.summary()\n",
    "\n",
    "optimizer = Adam() # higher leraning rate for D\n",
    "discriminator_c.compile(optimizer=optimizer, loss={'gan_output':'binary_crossentropy','style_output':'categorical_crossentropy'},\n",
    "                      loss_weights=[1.0, 0.5],\n",
    "                    metrics={'gan_output':'binary_accuracy', 'style_output':'categorical_accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "drum_input (InputLayer)      (None, 32, 9)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 32, 128)           37888     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 32, 256)           263168    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 32, 32)            34944     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "gan_output (Dense)           (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 992,385\n",
      "Trainable params: 992,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_a = Model(drum_input, output)\n",
    "discriminator_a.summary()\n",
    "\n",
    "optimizer = Adam() # higher leraning rate for D\n",
    "discriminator_a.compile(optimizer=optimizer, \n",
    "                        loss={'gan_output':'binary_crossentropy'},\n",
    "                    metrics={'gan_output':'binary_accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'gan_output_loss', 'style_output_loss', 'gan_output_binary_accuracy', 'style_output_categorical_accuracy']\n",
      "['loss', 'binary_accuracy']\n"
     ]
    }
   ],
   "source": [
    "print discriminator_c.metrics_names \n",
    "print discriminator_a.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 14:42:41.994599 140360265770368 deprecation_wrapper.py:119] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0826 14:42:42.002454 140360265770368 deprecation.py:506] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32, 256)           279552    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 32, 256)           525312    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32, 9)             9576      \n",
      "=================================================================\n",
      "Total params: 866,152\n",
      "Trainable params: 866,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Reshape, Conv2DTranspose, RepeatVector, Activation,Bidirectional,multiply\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "\n",
    "len_input = 100\n",
    "\n",
    "z_input = Input(shape=(len_input,))  # tensorflow order\n",
    "\n",
    "# # Conditioning label\n",
    "# label_input = Input(shape=(1,), dtype='int32')\n",
    "# label_embedding = Embedding(NB_GENRES, len_input, input_length=1)(label_input)\n",
    "# label_embedding = Flatten()(label_embedding)\n",
    "\n",
    "# # Element-wise product of the vectors z and the label embeddings\n",
    "# inputs2 = multiply([z_input, label_embedding])\n",
    "\n",
    "# \n",
    "x = Dense(512)(z_input)\n",
    "x = LeakyReLU(alpha=0.2)(x)\n",
    "#x = BatchNormalization(momentum=0.9)(x)\n",
    "# x = Dense(2048)(x)\n",
    "# x = LeakyReLU(alpha=0.2)(x)\n",
    "#x = BatchNormalization(momentum=0.9)(x)\n",
    "x = Reshape((32, 16))(x)\n",
    "x = Dropout(dropout_rate)(x)\n",
    "\n",
    "x = LSTM(256, return_sequences=True, activation='tanh')(x) \n",
    "x = LSTM(256, return_sequences=True, activation='tanh')(x)\n",
    "note_out = LSTM(9, return_sequences=True, activation='relu')(x)\n",
    "#note_out = LeakyReLU()(x)\n",
    "\n",
    "# # decoder for note\n",
    "# x = Dense(64, activation='relu')(z_input)\n",
    "# x = Dropout(dropout_rate)(x)\n",
    "# x = Dense(256, activation='relu')(x)\n",
    "# x = Dropout(dropout_rate)(x)\n",
    "# x1 = Dense(512, activation='relu')(x)\n",
    "# x = Dropout(dropout_rate)(x1)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# x = Dropout(dropout_rate)(x)\n",
    "# x = Dense(512, activation='relu')(x)\n",
    "# x = Dropout(dropout_rate)(x)\n",
    "# x = Dense(288, activation='sigmoid')(x) # output range shoud be 0. - 1.\n",
    "# note_out = Reshape((len_seq, nb_notes), name='note_output')(x)\n",
    "\n",
    "generator = Model(z_input, note_out)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADVERSARIAL MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_ambiguity_loss(y_true, y_pred):\n",
    "    even_dist = K.ones_like(y_pred) * 1.0/float(len(GENRES))\n",
    "    return K.categorical_crossentropy(even_dist, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0826 14:42:44.665159 140360265770368 deprecation.py:323] From /home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3298: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'model_1/gan_output/Sigmoid:0' shape=(?, 1) dtype=float32>, <tf.Tensor 'model_1/style_output/Softmax:0' shape=(?, 7) dtype=float32>]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, 32, 9)             866152    \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              [(None, 1), (None, 7)]    1650312   \n",
      "=================================================================\n",
      "Total params: 2,516,464\n",
      "Trainable params: 866,152\n",
      "Non-trainable params: 1,650,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "# define input for the combined GAN model\n",
    "z_input = Input(shape=(len_input,))  # tensorflow order\n",
    "img_gan = generator(z_input)\n",
    "\n",
    "# training is disable for discriminator in adversarial model\n",
    "discriminator_c.trainable = False \n",
    "\n",
    "# define output\n",
    "prediction_gan = discriminator_c(img_gan)\n",
    "print(prediction_gan)\n",
    "\n",
    "# define combined GAN model\n",
    "gan = Model(z_input, prediction_gan)\n",
    "optimizer = Adam()\n",
    "gan.compile(optimizer=optimizer, loss=['binary_crossentropy', style_ambiguity_loss], \n",
    "            loss_weights=[1.0, 0.5], metrics=['binary_accuracy'])\n",
    "gan.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss',\n",
       " 'model_1_loss',\n",
       " 'model_1_loss',\n",
       " 'model_1_binary_accuracy',\n",
       " 'model_1_binary_accuracy_1']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Create Z for generator\n",
    "def get_noise(batch_size, len_input):\n",
    "#    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, len_input])\n",
    "    \n",
    "    # better to use a spherical Z. according to https://github.com/soumith/ganhacks\n",
    "    noise = np.random.normal(0.0, 0.50, size=[batch_size, len_input])\n",
    "    return noise\n",
    "\n",
    "def plot_drum_matrix(a):\n",
    "    if a is not None:\n",
    "        a = np.transpose(np.squeeze(a))\n",
    "        plt.matshow(a)\n",
    "        plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir=/tmp/tf_logs/20190826-144245/\n"
     ]
    }
   ],
   "source": [
    "from tensorboard_logger import configure, log_value\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "logdir = \"/tmp/tf_logs/\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "cmd = \"tensorboard --logdir=\" + logdir\n",
    "print cmd\n",
    "\n",
    "configure(logdir, flush_secs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nao/anaconda3/envs/p2/lib/python2.7/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical \n",
    "\n",
    "batch_size = 32\n",
    "nb_epochs = 500\n",
    "nb_samples = matrices_drums.shape[0]\n",
    "\n",
    "K_unrolled = 1\n",
    "MAX_LOSS_RATIO = 3.0\n",
    "\n",
    "# Labels for real drums: all ones\n",
    "real_labels = np.ones((batch_size, 1)) # one-sided soft labeling for better stability\n",
    "\n",
    "# Labels for fake drums: all zeros\n",
    "fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "train_d = True\n",
    "train_g = True\n",
    "\n",
    "for epoch in range(0, nb_epochs):\n",
    "    nb_steps = int(nb_samples/batch_size)\n",
    "    \n",
    "    for repeat in range(nb_steps):\n",
    "        step = nb_steps * epoch + repeat\n",
    "        \n",
    "        if train_d:\n",
    "            \n",
    "            m_d_loss = 0.0\n",
    "            m_d_accuracy = 0.0\n",
    "            m_d_accuracy_fake, m_d_accuracy_real = 0.0, 0.0\n",
    "            m_d_loss_cat = 0.0\n",
    "            m_d_cat_accuracy = 0.0\n",
    "            \n",
    "            for j in range(K_unrolled):\n",
    "                # training data\n",
    "                random_indices = np.random.randint(0, matrices_drums.shape[0], size=batch_size)\n",
    "                drum_train = matrices_drums[random_indices, :, :]\n",
    "                labels_traing = matrices_genres[random_indices]\n",
    "                labels_traing_categorical = to_categorical(labels_traing, num_classes=NB_GENRES)\n",
    "\n",
    "                # generated samples\n",
    "                noise = get_noise(batch_size, len_input)\n",
    "                drum_fake = generator.predict(noise)\n",
    "\n",
    "                # training D\n",
    "                _, d_loss_real, d_loss_cat, d_acc_real, cat_accuracy = discriminator_c.train_on_batch(drum_train, [real_labels, labels_traing_categorical]) \n",
    "                d_loss_fake, d_acc_fake = discriminator_a.train_on_batch(drum_fake, fake_labels) \n",
    "    \n",
    "                m_d_loss += 0.5 * (d_loss_real + d_loss_fake)\n",
    "                m_d_loss_cat += d_loss_cat\n",
    "                m_d_accuracy +=  0.5 * (d_acc_real + d_acc_fake)\n",
    "                m_d_accuracy_fake += d_acc_fake\n",
    "                m_d_accuracy_real += d_acc_real\n",
    "                m_d_cat_accuracy += cat_accuracy\n",
    "                # cache for later update\n",
    "    #             cache_weights = discriminator.get_weights()\n",
    "            \n",
    "            m_d_loss /= float(K_unrolled)\n",
    "            m_d_accuracy /= float(K_unrolled)\n",
    "            m_d_accuracy_fake /= float(K_unrolled)\n",
    "            m_d_accuracy_real /= float(K_unrolled)\n",
    "            m_d_loss_cat /= float(K_unrolled)\n",
    "            m_d_cat_accuracy /= float(K_unrolled)\n",
    "           \n",
    "            # store value\n",
    "            log_value(\"D loss\", m_d_loss, step)  \n",
    "            log_value(\"D accuracy\", m_d_accuracy, step)  \n",
    "            log_value(\"D accuracy - fake\", m_d_accuracy_fake, step) \n",
    "            log_value(\"D accuracy - real\", m_d_accuracy_real, step) \n",
    "            \n",
    "            log_value(\"D category loss\", m_d_loss_cat, step)  \n",
    "            log_value(\"D category accuracy\", m_d_cat_accuracy, step) \n",
    "            log_value(\"D total loss\", m_d_loss + m_d_loss_cat, step)\n",
    "            \n",
    "        # training G\n",
    "        if train_g:\n",
    "            y = np.ones([batch_size, 1]) # watch out the label! it should be one here        \n",
    "\n",
    "            noise = get_noise(batch_size, len_input)\n",
    "\n",
    "            # Get a batch of random labels\n",
    "            labels_random = np.random.randint(0, NB_GENRES, batch_size).reshape(-1, 1)\n",
    "\n",
    "            _, m_a_loss, m_a_cat_loss, m_a_accuracy, _ = gan.train_on_batch(noise, [y, labels_random])\n",
    "            \n",
    "            # store value\n",
    "            log_value(\"G loss\", m_a_loss, step)\n",
    "            log_value(\"G accuracy\", m_a_accuracy, step)\n",
    "            log_value(\"style amguity loss\", m_a_cat_loss, step)\n",
    "            log_value(\"G total loss\", m_a_loss + m_a_cat_loss, step)\n",
    "        \n",
    "        if train_d and train_g:\n",
    "            if m_a_loss / m_d_loss > MAX_LOSS_RATIO:\n",
    "                train_d = False\n",
    "                print \"Pausing D\"\n",
    "            elif m_d_loss / m_a_loss > MAX_LOSS_RATIO:\n",
    "                train_g = False\n",
    "                print \"Pausing G\"\n",
    "        else:\n",
    "            train_d = True\n",
    "            train_g = True\n",
    "            \n",
    "        # update layer \n",
    "#         discriminator.set_weights(cache_weights)\n",
    " \n",
    "        if repeat % 100 == 0:\n",
    "            \n",
    "            print(\"epoch\", epoch, repeat)\n",
    "            print(\"d_loss\", m_d_loss, \"d_cat_acc\", m_d_cat_accuracy,\n",
    "                \"a_loss\", m_a_loss, 'a_cat_loss', m_a_cat_loss) # print mean loss)\n",
    "            print(\"d_accuracy\", m_d_accuracy )\n",
    "            \n",
    "            # sample output\n",
    "            noise = get_noise(1, len_input)\n",
    "            drum_generated = generator.predict(noise)           \n",
    "            plot_drum_matrix(drum_generated)\n",
    "            \n",
    "            print\n",
    "            print\n",
    "            \n",
    "                        \n",
    "    # store temporary models\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        generator.save(\"./tmp/can3_generator-epoch-%03d-%0.5f.h5\" % (epoch, m_a_loss))\n",
    "        gan.save(\"./tmp/can3_gan-epoch-%03d-%0.5f.h5\" % (epoch, m_a_loss))\n",
    "        discriminator_c.save(\"./tmp/can3_discriminator_c-epoch-%03d-%0.5f.h5\" % (epoch, m_d_loss))\n",
    "        discriminator_a.save(\"./tmp/can3_discriminator_a-epoch-%03d-%0.5f.h5\" % (epoch, m_d_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save(\"./tmp/can_generator.h5\")\n",
    "gan.save(\"./tmp/can_gan.h5\")\n",
    "discriminator.save(\"./tmp/can_discriminator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    noise = get_noise(1, len_input)\n",
    "    drum_generated = generator.predict(noise)\n",
    "    plot_drum_matrix(drum_generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MIDI Playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi playback\n",
    "def note_matrix_to_sequence(mat, threshold = 0.5):\n",
    "    seq = []\n",
    "    for row in mat[:]:\n",
    "        arow = [[i, r] for i, r in enumerate(row) if r > threshold]\n",
    "        seq.append(arow)\n",
    "    return seq\n",
    "\n",
    "import OSC\n",
    "max_poly = 6 # maximum number of instruments played at the same time\n",
    "\n",
    "client = OSC.OSCClient()\n",
    "client.connect( ('10.0.1.14', 2014) ) \n",
    "\n",
    "def send_sequence_via_osc(seq):\n",
    "    ## the most basic ##\n",
    "    msg = OSC.OSCMessage()\n",
    "    msg.setAddress(\"/seq\")\n",
    "    msg.append(max_poly * 2)\n",
    "    \n",
    "    for notes in seq:\n",
    "        for i in range(max_poly):\n",
    "            if len(notes) > i:\n",
    "                msg.append([notes[i][0]+min_drum_note, notes[i][1]])\n",
    "            else:\n",
    "                msg.append([0, 0])\n",
    "    client.send(msg)\n",
    "    \n",
    "def playback_seq_via_osc(mat):\n",
    "    send_sequence_via_osc(note_matrix_to_sequence(mat, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "repeat = 1\n",
    "\n",
    "for j in range(100):\n",
    "    noise1 = get_noise(1, len_input) \n",
    "    noise2 = get_noise(1, len_input) \n",
    "    \n",
    "    for i in range(repeat):\n",
    "        noise = noise1 * (1.0 - i/float(repeat)) + noise2 * i/float(repeat)\n",
    "        drum_generated = generator.predict(noise)\n",
    "        mat = np.squeeze(drum_generated)\n",
    "        playback_seq_via_osc(mat)\n",
    "        time.sleep(4.0)\n",
    "        clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
